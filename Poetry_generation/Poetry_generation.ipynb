{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost Shakespeare\n",
    "\n",
    "Let's try to generate some Shakespeare poetry using RNNs. The sonnets file is available in the notebook directory.\n",
    "\n",
    "Text generation can be designed in several steps:\n",
    "    \n",
    "1. Data loading.\n",
    "2. Dictionary generation.\n",
    "3. Data preprocessing.\n",
    "4. Model (neural network) training.\n",
    "5. Text generation (model evaluation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`).\n",
    "\n",
    "Simple preprocessing is already done for you in the next cell: all technical info is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('../../datasets/Shakespeare_sonnets/sonnets.txt', 'r') as iofile:\n",
    "        text = iofile.readlines()\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Shakespeare_sonnets/sonnets.txt -nc\n",
    "    with open('sonnets.txt', 'r') as iofile:\n",
    "        text = iofile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START : TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "OK!\n"
    }
   ],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "\n",
    "text=\"\".join([t.lower() for t in text])\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the characters, that you've seen in the text, into variable `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['\\n',\n ' ',\n '!',\n \"'\",\n '(',\n ')',\n ',',\n '-',\n '.',\n ':',\n ';',\n '?',\n 'a',\n 'b',\n 'c',\n 'd',\n 'e',\n 'f',\n 'g',\n 'h',\n 'i',\n 'j',\n 'k',\n 'l',\n 'm',\n 'n',\n 'o',\n 'p',\n 'q',\n 'r',\n 's',\n 't',\n 'u',\n 'v',\n 'w',\n 'x',\n 'y',\n 'z']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enmbending(index, size):\n",
    "    embending=np.zeros(size)\n",
    "    embending[index] = 1\n",
    "    return embending\n",
    "\n",
    "tokens_quant = len(tokens)\n",
    "\n",
    "# dict <index>:<char>\n",
    "idx_to_token = {tuple(create_enmbending(tokens.index(t), tokens_quant))  : t for t in tokens }\n",
    "\n",
    "\n",
    "# dict <char>:<index>\n",
    "\n",
    "token_to_idx = {t : create_enmbending(tokens.index(t), tokens_quant) for t in tokens }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
    "\n",
    "Let's use vanilla RNN, similar to the one created during the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.rnn_update = nn.Linear(tokens_quant + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, len(tokens))\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "\n",
    "        # compute next hidden state using self.rnn_update\n",
    "        # hint: use torch.cat(..., dim=...) for concatenation\n",
    "        x_and_h = torch.cat([x, h_prev], dim=1) # YOUR CODE HERE\n",
    "        h_next = self.rnn_update(x_and_h) # YOUR CODE HERE\n",
    "        \n",
    "        h_next = torch.tanh(h_next) # YOUR CODE HERE\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = self.rnn_to_logits(h_next)# YOUR CODE\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length, _ = batch_ix.size()\n",
    "\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "\n",
    "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного подготовим данные: сделаем все строки ожинаковой длины, добавив в конец нужное кол-во ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = text.split('\\n')\n",
    "#  Уберем пустые строки и строки заголовков\n",
    "string_list = [i for i in string_list if len(i)>8]\n",
    "MAX_LENGTH = max([len(s) for s in string_list])\n",
    "string_list_fullfilled = [s+' '*(MAX_LENGTH - len(s)) for s in string_list]\n",
    "add_embd = lambda input: [token_to_idx[s] for s in input]\n",
    "string_list_fullfilled = [add_embd(s) for s in string_list_fullfilled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 392.14375 262.19625\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 392.14375 262.19625 \nL 392.14375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 224.64 \nL 384.94375 224.64 \nL 384.94375 7.2 \nL 50.14375 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m1844dc8419\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m1844dc8419\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(62.180682 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"116.258861\" xlink:href=\"#m1844dc8419\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(109.896361 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.15579\" xlink:href=\"#m1844dc8419\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(157.61204 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.052719\" xlink:href=\"#m1844dc8419\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(208.508969 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"268.949648\" xlink:href=\"#m1844dc8419\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(259.405898 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.846578\" xlink:href=\"#m1844dc8419\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(310.302828 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.743507\" xlink:href=\"#m1844dc8419\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(361.199757 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(202.232813 252.916562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m65880a4d24\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m65880a4d24\" y=\"199.701737\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.25 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(20.878125 203.500956)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m65880a4d24\" y=\"169.736996\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.50 -->\n      <g transform=\"translate(20.878125 173.536215)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m65880a4d24\" y=\"139.772255\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.75 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(20.878125 143.571474)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m65880a4d24\" y=\"109.807514\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 2.00 -->\n      <g transform=\"translate(20.878125 113.606733)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m65880a4d24\" y=\"79.842774\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 2.25 -->\n      <g transform=\"translate(20.878125 83.641992)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m65880a4d24\" y=\"49.878033\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2.50 -->\n      <g transform=\"translate(20.878125 53.677251)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m65880a4d24\" y=\"19.913292\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2.75 -->\n      <g transform=\"translate(20.878125 23.71251)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Loss -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(14.798438 126.973906)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"55.697266\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"116.878906\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"168.978516\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p476f93d611)\" d=\"M 65.361932 17.083636 \nL 66.37987 59.866927 \nL 67.397809 85.620506 \nL 69.433686 116.211874 \nL 70.451625 126.758056 \nL 71.469563 134.588717 \nL 72.487502 140.539409 \nL 73.50544 145.386829 \nL 75.541318 153.095711 \nL 77.577195 159.104356 \nL 79.613072 163.946848 \nL 80.631011 166.289615 \nL 82.666888 169.845459 \nL 84.702765 173.100577 \nL 85.720703 174.502659 \nL 89.792458 178.815569 \nL 94.882151 183.088414 \nL 95.900089 183.69841 \nL 96.918028 184.576441 \nL 99.971844 186.556257 \nL 100.989782 187.057176 \nL 102.007721 187.773548 \nL 103.025659 188.128013 \nL 105.061537 189.29901 \nL 107.097414 190.084538 \nL 108.115352 190.751302 \nL 116.258861 193.839104 \nL 122.366492 195.728446 \nL 123.384431 195.962817 \nL 125.420308 196.59939 \nL 128.474124 197.376273 \nL 130.510001 197.821168 \nL 133.563817 198.611297 \nL 135.599694 198.901192 \nL 137.635571 199.362733 \nL 141.707326 200.277241 \nL 142.725264 200.225403 \nL 143.743203 200.616631 \nL 148.832896 201.448725 \nL 149.850834 201.72286 \nL 154.940527 202.555283 \nL 155.958466 202.8068 \nL 157.994343 202.877169 \nL 162.066097 203.597014 \nL 164.101974 203.825613 \nL 165.119913 204.089289 \nL 166.137852 203.973139 \nL 168.173729 204.41902 \nL 172.245483 204.818893 \nL 173.263422 204.845069 \nL 174.28136 205.19909 \nL 175.299299 205.150781 \nL 176.317237 205.398326 \nL 188.5325 206.678515 \nL 189.550439 206.554778 \nL 190.568378 206.862034 \nL 192.604255 206.907685 \nL 194.640132 207.08316 \nL 195.65807 207.218227 \nL 196.676009 207.211954 \nL 198.711886 207.501435 \nL 200.747763 207.755596 \nL 201.765702 207.579807 \nL 202.783641 207.801447 \nL 210.927149 208.394269 \nL 211.945088 208.327171 \nL 212.963026 208.539138 \nL 218.052719 208.772194 \nL 219.070658 208.992334 \nL 220.088596 208.990591 \nL 222.124474 209.211188 \nL 225.178289 209.254224 \nL 226.196228 209.473493 \nL 227.214167 209.430713 \nL 231.285921 209.707635 \nL 232.303859 209.716579 \nL 233.321798 209.897941 \nL 236.375614 209.991758 \nL 239.42943 210.283854 \nL 240.447368 210.093676 \nL 241.465307 210.291069 \nL 242.483245 210.278181 \nL 243.501184 210.425536 \nL 244.519122 210.297728 \nL 246.555 210.615542 \nL 248.590877 210.584408 \nL 254.698508 211.02313 \nL 255.716447 210.964734 \nL 258.770263 211.141509 \nL 263.859956 211.44435 \nL 264.877894 211.471783 \nL 265.895833 211.325499 \nL 266.913771 211.493258 \nL 293.380174 212.517015 \nL 294.398113 212.473707 \nL 295.416052 212.622406 \nL 297.451929 212.619491 \nL 300.505745 212.817341 \nL 301.523683 212.872765 \nL 302.541622 212.720552 \nL 306.613376 212.957181 \nL 309.667192 213.062671 \nL 310.68513 213.035452 \nL 311.703069 213.146401 \nL 313.738946 213.197996 \nL 319.846578 213.433996 \nL 320.864516 213.352638 \nL 322.900393 213.438225 \nL 325.954209 213.624387 \nL 326.972148 213.484262 \nL 329.008025 213.659065 \nL 330.025963 213.581579 \nL 332.061841 213.736565 \nL 335.115656 213.887135 \nL 336.133595 213.801205 \nL 337.151534 213.980437 \nL 339.187411 213.910196 \nL 341.223288 214.021173 \nL 343.259165 214.061038 \nL 344.277104 213.847042 \nL 345.295042 214.068768 \nL 346.312981 214.07424 \nL 347.330919 214.221052 \nL 369.725568 214.756364 \nL 369.725568 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 224.64 \nL 50.14375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 384.94375 224.64 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 224.64 \nL 384.94375 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 7.2 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 326.628125 29.878125 \nL 377.94375 29.878125 \nQ 379.94375 29.878125 379.94375 27.878125 \nL 379.94375 14.2 \nQ 379.94375 12.2 377.94375 12.2 \nL 326.628125 12.2 \nQ 324.628125 12.2 324.628125 14.2 \nL 324.628125 27.878125 \nQ 324.628125 29.878125 326.628125 29.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 328.628125 20.298437 \nL 348.628125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_17\">\n     <!-- loss -->\n     <defs>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(356.628125 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p476f93d611\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "history = []\n",
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(300):\n",
    "\n",
    "    shufeled = string_list_fullfilled\n",
    "    random.shuffle(shufeled)\n",
    "\n",
    "    batch_history=[]\n",
    "    # print(shufeled)\n",
    "    for i in range(0, len(shufeled) - batch_size + 1, batch_size):\n",
    "        # print(i)\n",
    "        batch_ix = shufeled[i:i+batch_size]\n",
    "        # batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
    "        batch_ix = torch.tensor(batch_ix, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "        \n",
    "        # compute loss\n",
    "        predictions_logp = logp_seq[:, :-1, :]# YOUR CODE HERE\n",
    "        actual_next_tokens = batch_ix[:, 1:, :]# YOUR CODE HERE\n",
    "        \n",
    "\n",
    "        loss = criterion(\n",
    "            predictions_logp.contiguous().view(-1, tokens_quant),\n",
    "            torch.argmax(actual_next_tokens, dim=2).contiguous().view(-1))# YOUR CODE HERE\n",
    "        \n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        batch_history.append(loss.data.numpy())\n",
    "    history.append(np.mean(batch_history))\n",
    "    if (i+1)%1==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase='  hello', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs, \n",
    "        smaller temperature converges to the single most likely output.\n",
    "        \n",
    "    Be careful with the model output. This model waits logits (not probabilities/log-probabilities)\n",
    "    of the next symbol.\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor(x_sequence, dtype=torch.float32).T\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    # print(x_sequence)\n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        # print(x_sequence[:, i].view(1,-1).shape, hid_state.shape)\n",
    "        hid_state, out = char_rnn(x_sequence[:, i].view(1,-1), hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        # print(x_sequence.shape, x_sequence, hid_state.shape)\n",
    "        hid_state, out = char_rnn(x_sequence[:, -1].view(1,-1), hid_state)\n",
    "        # Be really careful here with the model output\n",
    "        p_next = F.softmax(out / temperature, dim=-1).data.numpy()[0]\n",
    "        # print(p_next)\n",
    "        # sample next token and push it back into x_sequence\n",
    "        # print(p_next.shape, len(tokens))\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        next_embd = create_enmbending(next_ix, tokens_quant)\n",
    "        torch_next_embd = torch.tensor(next_embd, dtype=torch.float32).view(1,-1).T\n",
    "        # print(x_sequence.shape, torch_next_embd.shape)\n",
    "        x_sequence = torch.cat([x_sequence, torch_next_embd], dim=1)\n",
    "    tmp = x_sequence.data.numpy()\n",
    "    return ''.join([idx_to_token[tuple([int(i) for i in ix])] for ix in x_sequence.T.data.numpy()])\n",
    "    # return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "temperature =  0.1 \n   hellons shall the worth the stard the worth the worth the st\ntemperature =  0.3 \n   hellons shall the worth the stard the worth the stard the wo\ntemperature =  0.5 \n   hellone,                                                    \ntemperature =  0.7 \n   hellone,                                                    \ntemperature =  0.9 \n   hellons seem the worth the though the stard the proud the wo\ntemperature =  1.2 \n   hellons shall the stard the proud the will my self the worth\ntemperature =  1.4 \n   hellone my seem the decelf ar thee the stard the stard the s\ntemperature =  1.6 \n   hellows be so doth be the worth the will my love then the st\ntemperature =  1.8 \n   hellons beauty be the stard the worth the strong thee be the\ntemperature =  2.0 \n   hellons from the worth the world my self the stant the strin\n"
    }
   ],
   "source": [
    "for i in np.linspace(0.1, 2, 10):\n",
    "    print('temperature = ', round(i,1), '\\n', generate_sample(char_rnn, temperature=i/10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More poetic model\n",
    "\n",
    "Let's use LSTM instead of vanilla RNN and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function of the number of epochs. Does the final loss become better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), lstm_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.lstm_num_units = lstm_num_units\n",
    "        \n",
    "        self.lstm_update = nn.LSTM(num_tokens, lstm_num_units)\n",
    "        self.lstm_to_logits = nn.Linear(lstm_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous lstm hidden states, containing matrix [batch, lstm_num_units] of float32\n",
    "        \"\"\"\n",
    "\n",
    "        # compute next hidden state using self.rnn_update\n",
    "        # hint: use torch.cat(..., dim=...) for concatenation\n",
    "        # x_and_h = torch.cat([x, h_prev], dim=1) # YOUR CODE HERE\n",
    "        # print(x.shape, h_prev.shape)\n",
    "        lstm_out, h_next = self.lstm_update(x, h_prev)  # YOUR CODE HERE\n",
    "        \n",
    "        # h_next = torch.tanh(h_next) # YOUR CODE HERE\n",
    "\n",
    "        \n",
    "        # assert h_next.size() == h_prev.size()\n",
    "\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = self.lstm_to_logits(lstm_out)# YOUR CODE\n",
    "\n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return torch.zeros(1, batch_size, self.lstm_num_units, requires_grad=True), torch.zeros(1, batch_size, self.lstm_num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(char_lstm, batch_ix):\n",
    "    \"\"\"\n",
    "\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length, _ = batch_ix.size()\n",
    "\n",
    "    hid_state= char_lstm.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "\n",
    "        hid_state, logp_next = char_lstm(x_t.view(1,batch_size,-1), hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 392.14375 262.19625\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 392.14375 262.19625 \nL 392.14375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 224.64 \nL 384.94375 224.64 \nL 384.94375 7.2 \nL 50.14375 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m52fc6b2dea\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m52fc6b2dea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(62.180682 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"116.258861\" xlink:href=\"#m52fc6b2dea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(109.896361 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.15579\" xlink:href=\"#m52fc6b2dea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(157.61204 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.052719\" xlink:href=\"#m52fc6b2dea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(208.508969 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"268.949648\" xlink:href=\"#m52fc6b2dea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(259.405898 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.846578\" xlink:href=\"#m52fc6b2dea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(310.302828 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.743507\" xlink:href=\"#m52fc6b2dea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(361.199757 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(202.232813 252.916563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m33f0e424b1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m33f0e424b1\" y=\"213.401008\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.00 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(20.878125 217.200226)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m33f0e424b1\" y=\"186.567678\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.25 -->\n      <g transform=\"translate(20.878125 190.366897)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m33f0e424b1\" y=\"159.734349\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.50 -->\n      <g transform=\"translate(20.878125 163.533568)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m33f0e424b1\" y=\"132.90102\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.75 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(20.878125 136.700238)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m33f0e424b1\" y=\"106.06769\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 2.00 -->\n      <g transform=\"translate(20.878125 109.866909)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m33f0e424b1\" y=\"79.234361\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2.25 -->\n      <g transform=\"translate(20.878125 83.03358)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m33f0e424b1\" y=\"52.401032\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2.50 -->\n      <g transform=\"translate(20.878125 56.20025)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m33f0e424b1\" y=\"25.567702\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 2.75 -->\n      <g transform=\"translate(20.878125 29.366921)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- Loss -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(14.798438 126.973906)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"55.697266\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"116.878906\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"168.978516\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pd9df39f33c)\" d=\"M 65.361932 17.083636 \nL 66.37987 60.890267 \nL 67.397809 80.916229 \nL 68.415748 88.305135 \nL 69.433686 93.032679 \nL 70.451625 99.047029 \nL 73.50544 119.20766 \nL 75.541318 128.851477 \nL 78.595133 138.499656 \nL 80.631011 143.305954 \nL 83.684826 148.865924 \nL 85.720703 152.147989 \nL 87.756581 154.920271 \nL 89.792458 157.508995 \nL 90.810396 158.795762 \nL 94.882151 163.099762 \nL 95.900089 163.929948 \nL 96.918028 165.131731 \nL 100.989782 168.319061 \nL 102.007721 169.081178 \nL 103.025659 170.018766 \nL 104.043598 170.550404 \nL 105.061537 171.397646 \nL 106.079475 172.082736 \nL 107.097414 172.587491 \nL 109.133291 173.981648 \nL 110.151229 174.589711 \nL 112.187107 175.640204 \nL 113.205045 176.246424 \nL 114.222984 176.622921 \nL 116.258861 177.803258 \nL 120.330615 179.581001 \nL 121.348554 180.256085 \nL 123.384431 180.94706 \nL 124.40237 180.597177 \nL 125.420308 181.557925 \nL 127.456185 182.659278 \nL 128.474124 182.826895 \nL 131.52794 184.100189 \nL 134.581755 184.849011 \nL 135.599694 185.356875 \nL 138.65351 186.183773 \nL 139.671448 186.621188 \nL 142.725264 187.503066 \nL 144.761141 188.072654 \nL 145.77908 188.165521 \nL 146.797018 188.614963 \nL 147.814957 188.803653 \nL 150.868773 189.678942 \nL 151.886711 189.84295 \nL 153.922589 190.416837 \nL 154.940527 190.505456 \nL 155.958466 190.723267 \nL 156.976404 191.236544 \nL 159.012281 191.618555 \nL 160.03022 191.892077 \nL 162.066097 192.285437 \nL 164.101974 192.852965 \nL 165.119913 192.936761 \nL 166.137852 193.163938 \nL 167.15579 193.531414 \nL 171.227544 194.316216 \nL 172.245483 193.532092 \nL 173.263422 194.585694 \nL 177.335176 195.527992 \nL 178.353115 195.829087 \nL 179.371053 195.804929 \nL 181.40693 196.268586 \nL 182.424869 196.324322 \nL 184.460746 196.812085 \nL 189.550439 197.688513 \nL 191.586316 198.070972 \nL 194.640132 198.572836 \nL 195.65807 198.798439 \nL 196.676009 198.830235 \nL 197.693948 199.21185 \nL 199.729825 199.338151 \nL 200.747763 199.618684 \nL 202.783641 199.875021 \nL 203.801579 200.073154 \nL 204.819518 200.114009 \nL 205.837456 200.348889 \nL 206.855395 200.357679 \nL 207.873333 200.699373 \nL 209.909211 200.823217 \nL 210.927149 201.134523 \nL 211.945088 201.300028 \nL 214.998904 201.533372 \nL 216.016842 201.775136 \nL 217.034781 201.868976 \nL 218.052719 202.09916 \nL 219.070658 202.118941 \nL 220.088596 202.360833 \nL 222.124474 202.522154 \nL 230.267982 203.615421 \nL 231.285921 203.600694 \nL 232.303859 203.909671 \nL 234.339737 203.951332 \nL 235.357675 204.246963 \nL 238.411491 204.508291 \nL 239.42943 204.750452 \nL 240.447368 204.744835 \nL 242.483245 205.119629 \nL 243.501184 205.121088 \nL 244.519122 205.234107 \nL 245.537061 205.223129 \nL 246.555 205.501244 \nL 253.68057 206.301925 \nL 254.698508 206.302219 \nL 255.716447 206.536767 \nL 256.734385 206.436363 \nL 259.788201 206.842929 \nL 261.824078 207.019284 \nL 262.842017 207.183087 \nL 264.877894 207.184738 \nL 267.93171 207.620117 \nL 268.949648 207.733239 \nL 269.967587 207.692679 \nL 270.985526 207.919664 \nL 272.003464 207.886998 \nL 274.039341 208.205072 \nL 275.05728 208.125922 \nL 276.075219 208.272132 \nL 277.093157 208.258108 \nL 280.146973 208.700922 \nL 282.18285 208.83229 \nL 283.200789 208.894589 \nL 284.218727 209.106169 \nL 292.362236 209.56435 \nL 293.380174 209.751389 \nL 294.398113 209.737788 \nL 295.416052 209.881464 \nL 296.43399 209.87563 \nL 297.451929 210.086558 \nL 298.469867 210.175983 \nL 299.487806 210.123139 \nL 300.505745 210.205028 \nL 301.523683 210.413883 \nL 302.541622 210.385733 \nL 303.55956 210.555742 \nL 304.577499 209.366934 \nL 305.595437 209.441747 \nL 306.613376 210.668211 \nL 308.649253 210.995255 \nL 309.667192 210.89361 \nL 310.68513 211.097757 \nL 311.703069 210.902388 \nL 312.721008 211.232451 \nL 313.738946 211.313342 \nL 314.756885 211.096285 \nL 315.774823 211.375347 \nL 316.792762 211.361822 \nL 318.828639 211.709927 \nL 319.846578 211.653807 \nL 320.864516 211.767185 \nL 321.882455 211.766827 \nL 324.936271 212.045748 \nL 331.043902 212.469484 \nL 333.079779 212.444124 \nL 334.097718 212.630664 \nL 335.115656 212.556785 \nL 336.133595 212.785447 \nL 337.151534 212.734663 \nL 339.187411 212.860976 \nL 346.312981 213.485155 \nL 347.330919 213.250153 \nL 348.348858 213.537385 \nL 350.384735 213.690721 \nL 351.402674 213.493312 \nL 352.420612 213.807957 \nL 355.474428 214.056227 \nL 356.492367 213.99673 \nL 357.510305 214.161819 \nL 360.564121 214.181773 \nL 362.599998 214.49057 \nL 363.617937 214.597269 \nL 364.635875 214.41094 \nL 366.671752 214.569625 \nL 369.725568 214.731362 \nL 369.725568 214.731362 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 224.64 \nL 50.14375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 384.94375 224.64 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 224.64 \nL 384.94375 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 7.2 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 326.628125 29.878125 \nL 377.94375 29.878125 \nQ 379.94375 29.878125 379.94375 27.878125 \nL 379.94375 14.2 \nQ 379.94375 12.2 377.94375 12.2 \nL 326.628125 12.2 \nQ 324.628125 12.2 324.628125 14.2 \nL 324.628125 27.878125 \nQ 324.628125 29.878125 326.628125 29.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 328.628125 20.298438 \nL 348.628125 20.298438 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_18\">\n     <!-- loss -->\n     <defs>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(356.628125 23.798438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd9df39f33c\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "history = []\n",
    "char_lstm = CharLSTMCell()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(char_lstm.parameters())\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(300):\n",
    "\n",
    "    shufeled = string_list_fullfilled\n",
    "    random.shuffle(shufeled)\n",
    "\n",
    "    batch_history=[]\n",
    "    # print(shufeled)\n",
    "    for i in range(0, len(shufeled) - batch_size + 1, batch_size):\n",
    "        # print(i)\n",
    "        batch_ix = shufeled[i:i+batch_size]\n",
    "        # batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
    "        batch_ix = torch.tensor(batch_ix, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        logp_seq = loop(char_lstm, batch_ix)\n",
    "        \n",
    "        # compute loss\n",
    "        predictions_logp = logp_seq[0, :, :-1, :]# YOUR CODE HERE\n",
    "        actual_next_tokens = batch_ix[:, 1:, :]# YOUR CODE HERE\n",
    "        \n",
    "        # print(predictions_logp.shape, actual_next_tokens.shape)\n",
    "        loss = criterion(\n",
    "            predictions_logp.contiguous().view(-1, tokens_quant),\n",
    "            torch.argmax(actual_next_tokens, dim=2).contiguous().view(-1))# YOUR CODE HERE\n",
    "        \n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        batch_history.append(loss.data.numpy())\n",
    "    history.append(np.mean(batch_history))\n",
    "    if (i+1)%1==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"LSTM didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
    "\n",
    "Evaluate the results visually, try to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_lstm(char_lstm, seed_phrase='  hello', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs, \n",
    "        smaller temperature converges to the single most likely output.\n",
    "        \n",
    "    Be careful with the model output. This model waits logits (not probabilities/log-probabilities)\n",
    "    of the next symbol.\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor(x_sequence, dtype=torch.float32).T\n",
    "    hid_state = char_lstm.initial_state(batch_size=1)\n",
    "    # print(x_sequence)\n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        # print(x_sequence[:, i].view(1,-1).shape, hid_state.shape)\n",
    "        hid_state, out = char_lstm(x_sequence[:, i].view(1, 1, -1), hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        # print(x_sequence.shape, x_sequence, hid_state.shape)\n",
    "        hid_state, out = char_lstm(x_sequence[:, -1].view(1, 1, -1), hid_state)\n",
    "        # Be really careful here with the model output\n",
    "        p_next = F.softmax(out / temperature, dim=-1).data.numpy()[0]\n",
    "        # print(p_next)\n",
    "        # sample next token and push it back into x_sequence\n",
    "        # print(p_next.shape, len(tokens))\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next[0])\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        next_embd = create_enmbending(next_ix, tokens_quant)\n",
    "        torch_next_embd = torch.tensor(next_embd, dtype=torch.float32).view(1,-1).T\n",
    "        # print(x_sequence.shape, torch_next_embd.shape)\n",
    "        x_sequence = torch.cat([x_sequence, torch_next_embd], dim=1)\n",
    "    tmp = x_sequence.data.numpy()\n",
    "    return ''.join([idx_to_token[tuple([int(i) for i in ix])] for ix in x_sequence.T.data.numpy()])\n",
    "    # return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "temperature =  0.1 \n   hellow the world shall state the world and ment,            \ntemperature =  0.3 \n   hellow the world be the world and they see                  \ntemperature =  0.5 \n   hellow the world be the world and they see                  \ntemperature =  0.7 \n   hellow the world be the world and they deep                 \ntemperature =  0.9 \n   hellow the world the world and then thou dost               \ntemperature =  1.2 \n   hellow the world the world and then thou dost               \ntemperature =  1.4 \n   hellow the world shall state the world and me,              \ntemperature =  1.6 \n   hellow the world the world and they dear sweet,             \ntemperature =  1.8 \n   hellow the see thee be this to the stand stand,             \ntemperature =  2.0 \n   hellow the see the stare thou thy self in thee,             \n"
    }
   ],
   "source": [
    "for i in np.linspace(0.1, 2, 10):\n",
    "    print('temperature = ', round(i,1), '\\n', generate_sample_lstm(char_lstm, temperature=i/10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)LSTM показала себя лучше как с точки зрения лосса, так и с точки зрения качества(например, она стабильно добивает  hello до логичного hellow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)При низкой температуре модели, особенно LSTM склонны загонять себя в цикл из частотных слов, такого не происходит при высокой температуре и слова оказываются более разнообразными так как температуры увеличивает вероятность отклониться от высоковероятной последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/usr/local/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type CharLSTMCell. It won't be checked for correctness upon loading.\n  \"type \" + obj.__name__ + \". It won't be checked \"\n"
    }
   ],
   "source": [
    "torch.save(char_lstm, 'lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "temperature =  0.1 \n   hellow the world the world and then thou dost               \ntemperature =  0.3 \n   hellow the world the world and then thou dost               \ntemperature =  0.5 \n   hellow the world the world and then thou dost               \ntemperature =  0.7 \n   hellow the world shall with the stand of men grown,         \ntemperature =  0.9 \n   hellow the world the stand of the truth not shade,          \ntemperature =  1.2 \n   hellow the world the stare thou thy self all thee,          \ntemperature =  1.4 \n   hellow the world shall i will be the will,                  \ntemperature =  1.6 \n   hellow the world be the will be the worth                   \ntemperature =  1.8 \n   hellow the world shall stand and my self and self,          \ntemperature =  2.0 \n   hellow the say the will be be then the love,                \n"
    }
   ],
   "source": [
    "for i in np.linspace(0.1, 2, 10):\n",
    "    print('temperature = ', round(i,1), '\\n', generate_sample_lstm(model, temperature=i/10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение и загрузка работают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
    "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
    "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
    "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}